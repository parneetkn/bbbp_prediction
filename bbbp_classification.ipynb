{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Author: Parneet\n",
        "#### Blood brain barrier permeability prediction using dataset provided in the paper-\n",
        "\n",
        "( https://www.mdpi.com/1420-3049/26/24/7428 )\n"
      ],
      "metadata": {
        "id": "pncE5ch9Se6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing rdkit\n",
        "# !pip install rdkit-pypi"
      ],
      "metadata": {
        "id": "nR5Gjh-cTfDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# https://www.rdkit.org/\n",
        "#https://github.com/rdkit/rdkit\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "\n"
      ],
      "metadata": {
        "id": "ZqSEp-CzJtQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataet\n",
        "data = pd.read_csv(\"bbbp_blood.csv\")\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "ij6kzeNMJDw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Canonical SMILES-\n",
        "#### Why?\n",
        "#### Read here- [Tutorial to SMILES and canonical SMILES explained with examples](https://luis-vollmers.medium.com/tutorial-to-smiles-and-canonical-smiles-explained-with-examples-fbc8a46ca29f)"
      ],
      "metadata": {
        "id": "56s_jHZbVrh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There might be one or more valid SMILES that can represent one compound\n",
        "def canonical_smiles(smiles):\n",
        "    mols = [Chem.MolFromSmiles(smi) for smi in smiles]\n",
        "    smiles = [Chem.MolToSmiles(mol) for mol in mols]\n",
        "    return smiles"
      ],
      "metadata": {
        "id": "MNXh1kzwQgfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Canonical SMILES for main dataset\n",
        "Canon_SMILES = canonical_smiles(data.smiles)\n",
        "len(Canon_SMILES)"
      ],
      "metadata": {
        "id": "TGwUPqJ1QnmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concat the smiles in the dataframe\n",
        "data['SMILES'] = Canon_SMILES\n",
        "data = data.drop(['smiles'], axis=1)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "cvBDXDOEQvLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there are any duplicate smiles\n",
        "# Create a list for duplicate smiles\n",
        "duplicates_smiles = data[data['SMILES'].duplicated()]['SMILES'].values\n",
        "len(duplicates_smiles)\n",
        "#no duplicate smiles are present in the dataset"
      ],
      "metadata": {
        "id": "ekKgq1yxRIVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate molecular descriptors using RDkit\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-g2MNrfHF2tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of all RDKit descriptor names\n",
        "descriptor_names = [desc[0] for desc in Descriptors._descList]\n",
        "# Create a calculator for the descriptors\n",
        "calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n",
        "# Function to compute descriptors from SMILES\n",
        "def compute_descriptors(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol:\n",
        "        return list(calculator.CalcDescriptors(mol))\n",
        "    else:\n",
        "        return [None] * len(descriptor_names)\n",
        "\n",
        "# Apply function to the dataset\n",
        "df_descriptors = data[\"SMILES\"].apply(compute_descriptors)\n",
        "# Convert list of descriptor values into a DataFrame\n",
        "df_descriptors = pd.DataFrame(df_descriptors.tolist(), columns=descriptor_names)\n",
        "# Concatenate original dataset with descriptor values\n",
        "df_final = pd.concat([data, df_descriptors], axis=1)\n",
        "\n",
        "print(\"RDKit descriptors generated and saved!\")\n"
      ],
      "metadata": {
        "id": "q7u2nwGHRXtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final #full dataframe with original columns and rdkit descriptors"
      ],
      "metadata": {
        "id": "91B6KmmMo6mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.isna().sum().sum() ##checking for any na values"
      ],
      "metadata": {
        "id": "LpG7lhFLX6g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if any columns have all zero values: safe to remove\n",
        "zero_cols = df_final.columns[(df_final == 0).all()]\n",
        "print(\"Columns with zero values-\")\n",
        "print(zero_cols)\n",
        "print(\"Original Shape \")\n",
        "print(df_final.shape)\n",
        "print(\"======\")\n",
        "if len(zero_cols) > 0:\n",
        "    print(f\"Removing {len(zero_cols)} columns with all zero values: {list(zero_cols)}\")\n",
        "    df_final = df_final.drop(columns=zero_cols)\n",
        "print(\"Shape after rem columms\")\n",
        "print(df_final.shape)"
      ],
      "metadata": {
        "id": "QvHhl37gYTly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML: Classification using Random Forest"
      ],
      "metadata": {
        "id": "Y19XgJGgY0JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting the labels into y variable\n",
        "y = df_final['p_np']\n",
        "y"
      ],
      "metadata": {
        "id": "-fY5i-e2US4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.value_counts()) #counting 0 and 1 labels"
      ],
      "metadata": {
        "id": "d8ZDoAP9Um-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#features to be trained using the ML models: X\n",
        "X = df_final.drop(['num',\t'name',\t'p_np',\t'SMILES'], axis = 1)\n",
        "X"
      ],
      "metadata": {
        "id": "B2NIWW-lUqFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "e92FTlMxUwCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe()"
      ],
      "metadata": {
        "id": "fKl-nSxMe6WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.30, random_state=0)\n",
        "#split ratio:\n",
        "#train:test = 70:30"
      ],
      "metadata": {
        "id": "NfFjaVz1VhBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "seKX-rNKWZcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature Scaling : Apply MinMaxScaler to scale the descriptors between 0 and 1.\n",
        "st_x= MinMaxScaler()\n",
        "X_train= st_x.fit_transform(X_train)   #call fit_transform() on train data\n",
        "X_test= st_x.transform(X_test)         #call transform() on test data\n",
        "\n",
        "# X_train"
      ],
      "metadata": {
        "id": "IYc3u82sXEk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_RF = RandomForestClassifier()\n",
        "model_RF.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fR_lhBktXLUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the test set result\n",
        "y_pred_RF= model_RF.predict(X_test)\n",
        "y_pred_RF;"
      ],
      "metadata": {
        "id": "bM7jVhddXXrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Evaluating the Model:\n",
        "\n",
        "print(\"Results for Random Forest Model:\\n\")\n",
        "\n",
        "# Accuracy Score\n",
        "print('Accuracy Score:', accuracy_score(y_test, y_pred_RF))\n",
        "print()\n",
        "\n",
        "# Confusion Matrix\n",
        "results = confusion_matrix(y_test, y_pred_RF)\n",
        "print('Confusion Matrix:')\n",
        "print(results)\n",
        "print()\n",
        "\n",
        "# Precision\n",
        "print('Precision Score:', precision_score(y_test, y_pred_RF))\n",
        "print()\n",
        "\n",
        "# Recall\n",
        "print('Recall Score:', recall_score(y_test, y_pred_RF))\n",
        "print()\n",
        "\n",
        "# F1 Score\n",
        "print('F1 Score:', f1_score(y_test, y_pred_RF))\n",
        "print()\n",
        "\n",
        "# ROC-AUC Score (for binary classification)\n",
        "print('ROC-AUC Score:', roc_auc_score(y_test, y_pred_RF))\n",
        "print()\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_RF))\n"
      ],
      "metadata": {
        "id": "V5WG9BRbXZlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance: RF Importance & SKBest\n"
      ],
      "metadata": {
        "id": "RsbkH43crtaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RANDOM FOREST IMPORTANCE\n",
        "# Get feature names and importances\n",
        "features = X.columns\n",
        "importances = model_RF.feature_importances_\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "indices = np.argsort(importances)[-10:]  # Select top 10 features\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title('Top 10 Features: RF Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center', height=0.5)\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices], fontsize=10)\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.savefig(\"feature_importance_RF.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CsGAR1k0zuvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SELECTkBEST\n",
        "k = 10  # Number of top features to select\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Get selected feature scores and names\n",
        "scores = selector.scores_\n",
        "selected_indices = np.argsort(scores)[-k:]  # Top k features\n",
        "\n",
        "# Get feature names and their scores\n",
        "selected_features = [X.columns[i] for i in selected_indices]\n",
        "selected_scores = [scores[i] for i in selected_indices]\n",
        "\n",
        "# Plot top 10 selected features\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title('Top 10 Features (SelectKBest)')\n",
        "plt.barh(range(k), selected_scores, color='b', align='center', height=0.5)\n",
        "plt.yticks(range(k), selected_features, fontsize=10)\n",
        "plt.xlabel('Feature Score')\n",
        "plt.savefig(\"feature_importance_skb.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kfEcToW_syjO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}